{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymachta/Challenges_and_fun/Qube/utils/Dataset_modification.py:11: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X_train_DE = X_train[X_train['COUNTRY']==1].loc[:, X_train.columns.str.contains('^(ID|DAY_ID|DE|GAS|COAL|CARBON)')]\n",
      "/home/ymachta/Challenges_and_fun/Qube/utils/Dataset_modification.py:13: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X_train_FR = X_train[X_train['COUNTRY']==0].loc[:, X_train.columns.str.contains('^(ID|DAY_ID|FR|GAS|COAL|CARBON)')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "from utils.Dataset_modification import *\n",
    "\n",
    "\n",
    "X_train = pd.read_csv(datasets+'X_train.csv') #datasets is defined in utils\n",
    "Y_train=pd.read_csv(datasets+'Y_train.csv')\n",
    "\n",
    "X_train_DE,Y_train_DE,X_train_FR,Y_train_FR=seperate_data_by_countries(X_train,Y_train)\n",
    "del X_train,Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(output,df):\n",
    "    term=output[0]\n",
    "    if not isinstance(term, np.ndarray):\n",
    "        return  100 *spearmanr(output, df[\"TARGET\"]).correlation\n",
    "    else:\n",
    "        return  [100 *spearmanr(output[:,i], df[\"TARGET\"]).correlation for i in range(len(term)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the French train set [19.299993481034463, 24.845637966522727, 23.84146208964189]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 TARGET   R-squared:                       0.028\n",
      "Model:                            OLS   Adj. R-squared:                  0.010\n",
      "Method:                 Least Squares   F-statistic:                     1.520\n",
      "Date:                Sat, 05 Aug 2023   Prob (F-statistic):             0.0858\n",
      "Time:                        16:56:26   Log-Likelihood:                -1214.6\n",
      "No. Observations:                 851   AIC:                             2463.\n",
      "Df Residuals:                     834   BIC:                             2544.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.1058      0.065      1.631      0.103      -0.022       0.233\n",
      "FR_CONSUMPTION       0.5968      1.524      0.392      0.696      -2.395       3.589\n",
      "FR_DE_EXCHANGE      -0.0382      0.059     -0.646      0.518      -0.154       0.078\n",
      "FR_NET_EXPORT       -0.0819      0.112     -0.732      0.465      -0.301       0.138\n",
      "FR_GAS              -0.0411      0.100     -0.411      0.681      -0.237       0.155\n",
      "FR_COAL             -0.0371      0.087     -0.425      0.671      -0.208       0.134\n",
      "FR_HYDRO             0.1253      0.066      1.902      0.057      -0.004       0.255\n",
      "FR_NUCLEAR           0.0890      0.182      0.490      0.624      -0.268       0.446\n",
      "FR_SOLAR            -0.0835      0.114     -0.731      0.465      -0.308       0.141\n",
      "FR_WINDPOW          -0.2451      0.336     -0.730      0.465      -0.904       0.413\n",
      "FR_RESIDUAL_LOAD    -0.7279      1.548     -0.470      0.638      -3.767       2.311\n",
      "FR_RAIN             -0.0385      0.038     -1.006      0.315      -0.114       0.037\n",
      "FR_WIND              0.0567      0.051      1.111      0.267      -0.044       0.157\n",
      "FR_TEMP             -0.0136      0.039     -0.348      0.728      -0.090       0.063\n",
      "GAS_RET              0.0298      0.036      0.827      0.409      -0.041       0.101\n",
      "COAL_RET            -0.0208      0.036     -0.581      0.561      -0.091       0.049\n",
      "CARBON_RET           0.0493      0.037      1.334      0.183      -0.023       0.122\n",
      "==============================================================================\n",
      "Omnibus:                      378.405   Durbin-Watson:                   2.072\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7312.495\n",
      "Skew:                           1.532   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.030   Cond. No.                         133.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \n",
      "\n",
      "\n",
      " Spearman correlation for the Deutsch train set [41.92243892176021, 42.8906196785662, 42.83712124819804]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 TARGET   R-squared:                       0.113\n",
      "Model:                            OLS   Adj. R-squared:                  0.089\n",
      "Method:                 Least Squares   F-statistic:                     4.673\n",
      "Date:                Sat, 05 Aug 2023   Prob (F-statistic):           2.23e-09\n",
      "Time:                        16:56:27   Log-Likelihood:                -902.95\n",
      "No. Observations:                 643   AIC:                             1842.\n",
      "Df Residuals:                     625   BIC:                             1922.\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.0050      0.098      0.051      0.959      -0.188       0.198\n",
      "DE_CONSUMPTION       0.4587      0.271      1.696      0.090      -0.073       0.990\n",
      "DE_FR_EXCHANGE       0.1878      0.074      2.543      0.011       0.043       0.333\n",
      "DE_NET_EXPORT       -0.1655      0.148     -1.117      0.264      -0.456       0.125\n",
      "DE_GAS              -0.1064      0.093     -1.143      0.253      -0.289       0.076\n",
      "DE_COAL             -0.2033      0.131     -1.550      0.122      -0.461       0.054\n",
      "DE_HYDRO             0.0382      0.044      0.866      0.387      -0.048       0.125\n",
      "DE_NUCLEAR          -0.1357      0.081     -1.667      0.096      -0.296       0.024\n",
      "DE_SOLAR            -0.3141      0.133     -2.359      0.019      -0.576      -0.053\n",
      "DE_WINDPOW          -0.6789      0.360     -1.887      0.060      -1.386       0.028\n",
      "DE_LIGNITE          -0.2020      0.113     -1.791      0.074      -0.423       0.019\n",
      "DE_RESIDUAL_LOAD    -0.1587      0.447     -0.355      0.723      -1.037       0.720\n",
      "DE_RAIN              0.0124      0.047      0.263      0.793      -0.080       0.105\n",
      "DE_WIND             -0.0408      0.062     -0.658      0.511      -0.163       0.081\n",
      "DE_TEMP              0.0090      0.047      0.194      0.846      -0.082       0.101\n",
      "GAS_RET              0.0144      0.040      0.356      0.722      -0.065       0.094\n",
      "COAL_RET            -0.0196      0.041     -0.476      0.634      -0.100       0.061\n",
      "CARBON_RET          -0.0271      0.041     -0.655      0.513      -0.108       0.054\n",
      "==============================================================================\n",
      "Omnibus:                      407.470   Durbin-Watson:                   1.944\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4775.846\n",
      "Skew:                           2.672   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.235   Cond. No.                         32.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_FR, Y_train_FR)\n",
    "print('Spearman correlation for the French train set', ( evaluation(lr.predict(X_train_FR),Y_train_FR)))\n",
    "X2 = sm.add_constant(X_train_FR)\n",
    "est = sm.OLS(Y_train_FR[\"TARGET\"], X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary(),\"\\n\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_DE, Y_train_DE)\n",
    "print('\\n Spearman correlation for the Deutsch train set', ( evaluation(lr.predict(X_train_DE),Y_train_DE)))\n",
    "X2 = sm.add_constant(X_train_DE)\n",
    "est = sm.OLS(Y_train_DE[\"TARGET\"], X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def average_stats(df,labels,regressor,columns=['TARGET','Rank'],iterations=20,depth=None,group=False,linear=False,custom_group=None):\n",
    "    valid_list=[]\n",
    "    train_list=[] \n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        if group :\n",
    "            columns+=['Rank_group']\n",
    "        if linear :\n",
    "            depth=None\n",
    "            _,X_test,_, y_test = train_test_split(df, labels, test_size=0.25)\n",
    "            X_train,Y_train =df,labels\n",
    "        else:\n",
    "            X_train, X_test, Y_train, y_test = train_test_split(df, labels, test_size=0.25)\n",
    "            Y_train['Rank']= Y_train['TARGET'].rank()\n",
    "            if custom_group is not None:\n",
    "                Y_train['Rank_group'+str(custom_group)]=pd.qcut(Y_train.Rank,custom_group).cat.codes\n",
    "                columns='Rank_group'+str(custom_group)\n",
    "        \n",
    "                \n",
    "        if depth is None:\n",
    "            DF = regressor()\n",
    "        else:            \n",
    "            DF = regressor(max_depth=depth)\n",
    "        #   Fit the ridge regressor\n",
    "        \n",
    "        DF.fit(X_train, Y_train[columns])\n",
    "        output_train = DF.predict(X_test)\n",
    "        # print(output_train)\n",
    "        validation=evaluation(output_train,y_test)\n",
    "        training=evaluation(DF.predict(X_train),Y_train)\n",
    "        valid_list+=[validation]\n",
    "        train_list+=[training]\n",
    "    print(columns)\n",
    "    if isinstance(columns,list):\n",
    "        for i,column in enumerate(columns):\n",
    "            print( f\"average {column} evaluation score at \", sum([row[i] for row in valid_list])/len(valid_list) , \"training at \", sum([row[i] for row in train_list])/len(train_list) )\n",
    "    else:\n",
    "        print( f\"average {columns} evaluation score at \", sum(valid_list)/len(valid_list) , \"training at :\" ,  sum(train_list)/len(train_list) )\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average TARGET evaluation score at  17.85260609065711 training at  53.82022568268769\n",
      "average Rank evaluation score at  20.023107841630267 training at  50.04896455932142\n",
      "\n",
      "\n",
      "average Rank evaluation score at  17.202484829344378 training at : 50.430705492453846\n",
      "\n",
      "\n",
      "average TARGET evaluation score at  10.630210263444384 training at : 32.87176932921054\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "average_stats(X_train_FR,Y_train_FR,RandomForestRegressor,depth=3)\n",
    "average_stats(X_train_FR,Y_train_FR,RandomForestRegressor,columns='Rank',depth=3)\n",
    "average_stats(X_train_FR,Y_train_FR,RandomForestRegressor,columns='TARGET',depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average TARGET evaluation score at  34.22718517399047 training at  62.35478460695815\n",
      "average Rank evaluation score at  35.078339797009605 training at  59.80129633196492\n",
      "\n",
      "\n",
      "average Rank evaluation score at  34.828691464329026 training at : 71.71266385255014\n",
      "\n",
      "\n",
      "average TARGET evaluation score at  24.927559706627523 training at : 48.71229455568933\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_stats(X_train_DE,Y_train_DE,RandomForestRegressor,depth=3)\n",
    "average_stats(X_train_DE,Y_train_DE,RandomForestRegressor,columns='Rank',depth=4)\n",
    "average_stats(X_train_DE,Y_train_DE,RandomForestRegressor,columns='TARGET',depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average TARGET evaluation score at  39.573785848998604 training at  41.92243892176021\n",
      "average Rank evaluation score at  40.83160758647242 training at  42.890619678566196\n",
      "\n",
      "\n",
      "average TARGET evaluation score at  19.139199982486524 training at  19.299993481034456\n",
      "average Rank evaluation score at  24.49062407274294 training at  24.845637966522716\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_stats(X_train_DE,Y_train_DE,LinearRegression,linear=True)\n",
    "\n",
    "average_stats(X_train_FR,Y_train_FR,LinearRegression,linear=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################  DE\n",
      "average TARGET evaluation score at  24.973635041433795 training at  22.889492618136938\n",
      "average Rank evaluation score at  45.13037868293989 training at  42.84383703531719\n",
      "average Rank_group evaluation score at  39.52151515674127 training at  36.83642992951844\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m##################  DE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m average_stats(X_train_DE,Y_train_DE,OrdinalRidge,linear\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,group\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m##################  FR\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m average_stats(X_train_FR,Y_train_FR,OrdinalRidge,linear\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,group\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[39], line 38\u001b[0m, in \u001b[0;36maverage_stats\u001b[0;34m(df, labels, regressor, columns, iterations, depth, group, linear, custom_group)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(columns,\u001b[39mlist\u001b[39m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m i,column \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(columns):\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m evaluation score at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m([row[i] \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m valid_list])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_list) , \u001b[39m\"\u001b[39m\u001b[39mtraining at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m([row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m train_list])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_list) )\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage \u001b[39m\u001b[39m{\u001b[39;00mcolumns\u001b[39m}\u001b[39;00m\u001b[39m evaluation score at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m(valid_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_list) , \u001b[39m\"\u001b[39m\u001b[39mtraining at :\u001b[39m\u001b[39m\"\u001b[39m ,  \u001b[39msum\u001b[39m(train_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_list) )\n",
      "Cell \u001b[0;32mIn[39], line 38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(columns,\u001b[39mlist\u001b[39m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m i,column \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(columns):\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m evaluation score at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m([row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m valid_list])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_list) , \u001b[39m\"\u001b[39m\u001b[39mtraining at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m([row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m train_list])\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_list) )\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maverage \u001b[39m\u001b[39m{\u001b[39;00mcolumns\u001b[39m}\u001b[39;00m\u001b[39m evaluation score at \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m(valid_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_list) , \u001b[39m\"\u001b[39m\u001b[39mtraining at :\u001b[39m\u001b[39m\"\u001b[39m ,  \u001b[39msum\u001b[39m(train_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_list) )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from mord import OrdinalRidge\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(\"##################  DE\")\n",
    "    average_stats(X_train_DE,Y_train_DE,OrdinalRidge,linear=True,group=True)\n",
    "    \n",
    "    print(\"##################  FR\")\n",
    "    average_stats(X_train_FR,Y_train_FR,OrdinalRidge,linear=True,group=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average Rank_group_2 evaluation score at  29.245032019594827 training at : 35.55958255971934\n",
      "\n",
      "\n",
      "##################  FR\n",
      "average Rank_group_2 evaluation score at  14.434407496364155 training at : 21.72433225801675\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "average_stats(X_train_DE,Y_train_DE,LogisticRegression,columns='Rank_group',custom_group=2)\n",
    "\n",
    "print(\"##################  FR\")\n",
    "average_stats(X_train_FR,Y_train_FR,LogisticRegression,columns='Rank_group',custom_group=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
